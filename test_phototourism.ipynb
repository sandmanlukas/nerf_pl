{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import load_ckpt, visualize_depth\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "\n",
    "import metrics\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from datasets import dataset_dict\n",
    "import json\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your settings...\n",
    "############################\n",
    "N_vocab = 800\n",
    "encode_appearance = True\n",
    "N_a = 48\n",
    "encode_transient = True\n",
    "N_tau = 16\n",
    "beta_min = 0.1 # doesn't have effect in testing\n",
    "ckpt_path = 'ckpts/IC_patient000_segment001_scale3_nerfw_mask/last.ckpt'\n",
    "\n",
    "N_emb_xyz = 10\n",
    "N_emb_dir = 4\n",
    "N_samples = 256\n",
    "N_importance = 256\n",
    "use_disp = False\n",
    "chunk = 1024*32\n",
    "#############################\n",
    "\n",
    "embedding_xyz = PosEmbedding(N_emb_xyz-1, N_emb_xyz)\n",
    "embedding_dir = PosEmbedding(N_emb_dir-1, N_emb_dir)\n",
    "embeddings = {'xyz': embedding_xyz, 'dir': embedding_dir}\n",
    "\n",
    "if encode_appearance:\n",
    "    embedding_a = torch.nn.Embedding(N_vocab, N_a).cuda()\n",
    "    load_ckpt(embedding_a, ckpt_path, model_name='embedding_a')\n",
    "    embeddings['a'] = embedding_a\n",
    "\n",
    "if encode_transient:\n",
    "    embedding_t = torch.nn.Embedding(N_vocab, N_tau).cuda()\n",
    "    load_ckpt(embedding_t, ckpt_path, model_name='embedding_t')\n",
    "    embeddings['t'] = embedding_t\n",
    "    \n",
    "\n",
    "nerf_coarse = NeRF('coarse',\n",
    "                   in_channels_xyz=6*N_emb_xyz+3,\n",
    "                   in_channels_dir=6*N_emb_dir+3).cuda()\n",
    "\n",
    "nerf_fine = NeRF('fine',\n",
    "                 in_channels_xyz=6*N_emb_xyz+3,\n",
    "                 in_channels_dir=6*N_emb_dir+3,\n",
    "                 encode_appearance=encode_appearance,\n",
    "                 in_channels_a=N_a,\n",
    "                 encode_transient=encode_transient,\n",
    "                 in_channels_t=N_tau,\n",
    "                 beta_min=beta_min).cuda()\n",
    "\n",
    "load_ckpt(nerf_coarse, ckpt_path, model_name='nerf_coarse')\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "\n",
    "models = {'coarse': nerf_coarse, 'fine': nerf_fine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def f(rays, ts, **kwargs):\n",
    "    \"\"\"Do batched inference on rays using chunk.\"\"\"\n",
    "    B = rays.shape[0]\n",
    "    results = defaultdict(list)\n",
    "    for i in range(0, B, chunk):\n",
    "        kwargs_ = {}\n",
    "        if 'a_embedded' in kwargs:\n",
    "            kwargs_['a_embedded'] = kwargs['a_embedded'][i:i+chunk]\n",
    "        rendered_ray_chunks = \\\n",
    "            render_rays(models,\n",
    "                        embeddings,\n",
    "                        rays[i:i+chunk],\n",
    "                        ts[i:i+chunk],\n",
    "                        N_samples,\n",
    "                        use_disp,\n",
    "                        0,\n",
    "                        0,\n",
    "                        N_importance,\n",
    "                        chunk,\n",
    "                        dataset.white_back,\n",
    "                        test_time=True,\n",
    "                        **kwargs_)\n",
    "\n",
    "        for k, v in rendered_ray_chunks.items():\n",
    "            results[k] += [v]\n",
    "\n",
    "    for k, v in results.items():\n",
    "        results[k] = torch.cat(v, 0)\n",
    "    del rendered_ray_chunks\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/IC_patient_000/segment_001/datasets/test/'\n",
    "\n",
    "dataset = dataset_dict['phototourism'] \\\n",
    "          (root_dir,\n",
    "           split='test_train',\n",
    "           img_downscale=3, use_cache=False, exp_name='IC_patient000_segment001_scale3_nerfw_mask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_test = dataset.img_ids_train[:5]\n",
    "len(img_ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir = '/home/jupyter/data/IC_patient_000/segment_001/datasets/train/mask.png'\n",
    "\n",
    "mask = Image.open(mask_dir).convert('L')\n",
    "\n",
    "mask_w, mask_h = mask.size\n",
    "\n",
    "mask_w = mask_w//3\n",
    "mask_h = mask_h//3\n",
    "\n",
    "\n",
    "mask = mask.resize((mask_w, mask_h), Image.Resampling.LANCZOS)\n",
    "mask = T.ToTensor()(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_img(mask, img):\n",
    "    img = img if torch.is_tensor(img) else torch.from_numpy(img)\n",
    "\n",
    "    mask = mask.permute(1,2,0)\n",
    "\n",
    "    return img * mask\n",
    "\n",
    "\n",
    "\n",
    "def plot_print_results(sample, result,mask, encode_transient):\n",
    "    img_wh = tuple(sample['img_wh'].numpy())\n",
    "    img_gt = sample['rgbs'].view(img_wh[1], img_wh[0], 3)\n",
    "    img_pred = result['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "    depth_pred = result['depth_fine'].view(img_wh[1], img_wh[0])\n",
    "\n",
    "    \n",
    "    masked_pred = masked_img(mask,img_pred).numpy()\n",
    "    \n",
    "    plt.subplots(figsize=(15, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(241)\n",
    "    plt.title('GT')\n",
    "    plt.imshow(img_gt)\n",
    "    plt.subplot(242)\n",
    "    plt.title('pred')\n",
    "    plt.imshow(img_pred)\n",
    "    plt.subplot(243)\n",
    "    plt.title('pred with mask')\n",
    "    plt.imshow(masked_pred)\n",
    "    plt.subplot(244)\n",
    "    plt.title('depth')\n",
    "    plt.imshow(visualize_depth(depth_pred).permute(1,2,0))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    psnr = metrics.psnr(img_gt, img_pred).item()\n",
    "    ssim = metrics.ssim(img_gt, img_pred).item()\n",
    "    lpips = metrics.lpips_score(img_gt, img_pred).item()\n",
    "\n",
    "    psnr_mask = metrics.psnr(img_gt, masked_pred).item()\n",
    "    ssim_mask = metrics.ssim(img_gt, masked_pred).item()\n",
    "    lpips_mask = metrics.lpips_score(img_gt, masked_pred).item()\n",
    "\n",
    "    print(f'{\"#\"*15} Scores for real predicition {\"#\"*15}')\n",
    "    print('PSNR between GT and pred:', psnr)\n",
    "    print('SSIM between GT and pred:', ssim)\n",
    "    print('LPIPS between GT and pred:',lpips, '\\n') \n",
    "\n",
    "    print(f'{\"#\"*15} Scores for masked predicition {\"#\"*15}')\n",
    "    print('PSNR between GT and pred:', psnr_mask)\n",
    "    print('SSIM between GT and pred:', ssim_mask)\n",
    "    print('LPIPS between GT and pred:',lpips_mask) \n",
    "\n",
    "\n",
    "\n",
    "    if encode_transient:\n",
    "        print('Decomposition--------------------------------------------' + \n",
    "            '---------------------------------------------------------' +\n",
    "            '---------------------------------------------------------' + \n",
    "            '---------------------------------------------------------')\n",
    "        valid_mask_static = sample['valid_mask'].view(img_wh[1], img_wh[0])\n",
    "        beta = result['beta'].view(img_wh[1], img_wh[0]).cpu().numpy()\n",
    "        img_pred_static = result['rgb_fine_static'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "        img_pred_transient = result['_rgb_fine_transient'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "        depth_pred_static = result['depth_fine_static'].view(img_wh[1], img_wh[0])\n",
    "        depth_pred_transient = result['depth_fine_transient'].view(img_wh[1], img_wh[0])\n",
    "        plt.subplots(figsize=(15, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(231)\n",
    "        plt.title('static')\n",
    "        plt.imshow(img_pred_static)\n",
    "        plt.subplot(232)\n",
    "        plt.title('transient')\n",
    "        plt.imshow(img_pred_transient)\n",
    "        plt.subplot(233)\n",
    "        plt.title('uncertainty (beta)')\n",
    "        plt.imshow(beta-beta_min, cmap='gray')\n",
    "        plt.subplot(234)\n",
    "        plt.title('static depth')\n",
    "        plt.imshow(visualize_depth(depth_pred_static).permute(1,2,0))\n",
    "        plt.subplot(235)\n",
    "        plt.title('valid mask')\n",
    "        plt.imshow(valid_mask_static, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    return psnr,psnr_mask, ssim, ssim_mask, lpips, lpips_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE TO CORRECT IMAGE\n",
    "\n",
    "results = {}\n",
    "samples = {}\n",
    "for id in img_ids_test:\n",
    "    print(f'Calculating results for id: {id}...')\n",
    "    sample = dataset[id]\n",
    "    samples[id] = sample\n",
    "    \n",
    "    rays = sample['rays'].cuda()\n",
    "    ts = sample['ts'].cuda()\n",
    "\n",
    "    results[id] = (f(rays, ts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = []\n",
    "ssims = []\n",
    "lpips_scores = []\n",
    "\n",
    "psnrs_mask = []\n",
    "ssims_mask = []\n",
    "lpips_scores_mask = []\n",
    "\n",
    "for id in img_ids_test:\n",
    "     sample = samples[id]\n",
    "     result = results[id]\n",
    "     \n",
    "     psnr,psnr_mask, ssim,ssim_mask, lpips, lpips_mask = plot_print_results(sample=sample, result=result,mask=mask, encode_transient=False)\n",
    "\n",
    "\n",
    "     psnrs.append(psnr)\n",
    "     ssims.append(ssim)\n",
    "     lpips_scores.append(lpips)\n",
    "\n",
    "     psnrs_mask.append(psnr_mask)\n",
    "     ssims_mask.append(ssim_mask)\n",
    "     lpips_scores_mask.append(lpips_mask)\n",
    "\n",
    "\n",
    "# Masked\n",
    "\n",
    "# PSNR\n",
    "mean_psnr = round(np.mean(psnrs_mask),2)\n",
    "median_psnr = round(np.median(psnrs_mask),2)\n",
    "max_psnr = round(np.max(psnrs_mask),2)\n",
    "min_psnr = round(np.min(psnrs_mask),2)\n",
    "\n",
    "# SSIM\n",
    "mean_ssim = round(np.mean(ssims_mask),3)\n",
    "median_ssim = round(np.median(ssims_mask),3)\n",
    "max_ssim = round(np.max(ssims_mask),3)\n",
    "min_ssim = round(np.min(ssims_mask),3)\n",
    "\n",
    "# LPIPS\n",
    "mean_lpips = round(np.mean(lpips_mask),3)\n",
    "median_lpips = round(np.median(lpips_mask),3)\n",
    "max_lpips = round(np.max(lpips_mask),3)\n",
    "min_lpips = round(np.min(lpips_mask),3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print('\\n',f'{\"#\"*15} Mean scores for true prediction {\"#\"*15}')\n",
    "# print(\"Mean PSNR: \", np.mean(psnrs))\n",
    "# print(\"Mean SSIM: \", np.mean(ssims))\n",
    "# print(\"Mean LPIPS: \", np.mean(lpips_scores), '\\n')\n",
    "\n",
    "print(f'{\"#\"*15} Mean scores for masked prediction {\"#\"*15}')\n",
    "print(\"Mean PSNR: \", mean_psnr)\n",
    "print(\"Mean SSIM: \", mean_ssim)\n",
    "print(\"Mean LPIPS: \", mean_lpips)\n",
    "\n",
    "data = {\n",
    "     'mean_psnr': mean_psnr,\n",
    "     'median_psnr': median_psnr,\n",
    "     'max_psnr': max_psnr,\n",
    "     'min_psnr': min_psnr,\n",
    "     'mean_ssim': mean_ssim,\n",
    "     'median_ssim': median_psnr,\n",
    "     'max_ssim': max_ssim,\n",
    "     'min_ssim': min_ssim,\n",
    "     'mean_lpips': mean_lpips,\n",
    "     'median_lpips': median_lpips,\n",
    "     'max_lpips': max_lpips,\n",
    "     'min_lpips': min_lpips\n",
    "}\n",
    "\n",
    "json_obj = json.dumps(data)\n",
    "with open(os.path.join(root_dir, 'results_nerfw.json'),'w') as file:\n",
    "     file.write(json_obj)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate embedding for appearance change (Fig 8 in the paper)\n",
    "### left image: train number 53; right image: train number 111\n",
    "### The pose is fixed to that of the right image, and the appearance embedding is interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_sample = dataset[53]\n",
    "# right_sample = dataset[111]\n",
    "\n",
    "# right_rays = right_sample['rays'].cuda()\n",
    "# right_ts = right_sample['ts'].cuda()\n",
    "# left_a_embedded = embedding_a(left_sample['ts'][0].cuda())\n",
    "# right_a_embedded = embedding_a(right_sample['ts'].cuda())\n",
    "\n",
    "# results_list = [left_sample]\n",
    "\n",
    "# for i in range(5):\n",
    "#     kwargs = {'a_embedded': right_a_embedded*i/4+left_a_embedded*(1-i/4)}\n",
    "#     results_list += [f(right_rays, right_ts, **kwargs)]\n",
    "\n",
    "# results_list += [right_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(20, 10))\n",
    "# for i, results in enumerate(results_list):\n",
    "#     if i == 0:\n",
    "#         img_wh = tuple(results['img_wh'].numpy())\n",
    "#         left_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(241)\n",
    "#         plt.axis('off')\n",
    "#         plt.title('left GT')\n",
    "#         plt.imshow(left_GT)\n",
    "#     elif i == 6:\n",
    "#         img_wh = tuple(results['img_wh'].numpy())\n",
    "#         right_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(247)\n",
    "#         plt.axis('off')\n",
    "#         plt.title('right GT')\n",
    "#         plt.imshow(right_GT)\n",
    "#     else:\n",
    "#         img_wh = tuple(right_sample['img_wh'].numpy())\n",
    "#         img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(2, 4, i+1)\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img_pred)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
