{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils import load_ckpt, visualize_depth\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "\n",
    "import metrics\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms as T\n",
    "from torchvision.io import write_png\n",
    "\n",
    "from datasets import dataset_dict\n",
    "import json\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your settings...\n",
    "############################\n",
    "N_vocab = 800\n",
    "encode_appearance = True\n",
    "N_a = 48\n",
    "encode_transient = True\n",
    "N_tau = 16\n",
    "beta_min = 0.1 # doesn't have effect in testing\n",
    "\n",
    "### Change to correct ckpts\n",
    "embedding_ckpt_path = '/home/lukas/exjobb-nerf/ckpts/OPEN_scale3_nerfw_optimize_appearance_top_bottom/last.ckpt'\n",
    "ckpt_path = '/home/lukas/exjobb-nerf/ckpts/OPEN_scale3_nerfw/last.ckpt'\n",
    "\n",
    "N_emb_xyz = 10\n",
    "N_emb_dir = 4\n",
    "N_samples = 256\n",
    "N_importance = 256\n",
    "use_disp = False\n",
    "chunk = 1024*32\n",
    "#############################\n",
    "\n",
    "embedding_xyz = PosEmbedding(N_emb_xyz-1, N_emb_xyz)\n",
    "embedding_dir = PosEmbedding(N_emb_dir-1, N_emb_dir)\n",
    "embeddings = {'xyz': embedding_xyz, 'dir': embedding_dir}\n",
    "\n",
    "if encode_appearance:\n",
    "    embedding_a = torch.nn.Embedding(N_vocab, N_a).cuda()\n",
    "    # load embedding from optimization\n",
    "    load_ckpt(embedding_a, embedding_ckpt_path, model_name='embedding_a')\n",
    "    embeddings['a'] = embedding_a\n",
    "\n",
    "if encode_transient:\n",
    "    embedding_t = torch.nn.Embedding(N_vocab, N_tau).cuda()\n",
    "    load_ckpt(embedding_t, ckpt_path, model_name='embedding_t')\n",
    "    embeddings['t'] = embedding_t\n",
    "    \n",
    "\n",
    "nerf_coarse = NeRF('coarse',\n",
    "                   in_channels_xyz=6*N_emb_xyz+3,\n",
    "                   in_channels_dir=6*N_emb_dir+3,\n",
    "                   encode_appearance=encode_appearance,\n",
    "                   in_channels_a=N_a,\n",
    "                   ).cuda()\n",
    "\n",
    "nerf_fine = NeRF('fine',\n",
    "                 in_channels_xyz=6*N_emb_xyz+3,\n",
    "                 in_channels_dir=6*N_emb_dir+3,\n",
    "                 encode_appearance=encode_appearance,\n",
    "                 in_channels_a=N_a,\n",
    "                 encode_transient=encode_transient,\n",
    "                 in_channels_t=N_tau,\n",
    "                 beta_min=beta_min).cuda()\n",
    "\n",
    "load_ckpt(nerf_coarse, ckpt_path, model_name='nerf_coarse')\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "\n",
    "models = {'coarse': nerf_coarse, 'fine': nerf_fine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def f(rays, ts, **kwargs):\n",
    "    \"\"\"Do batched inference on rays using chunk.\"\"\"\n",
    "    B = rays.shape[0]\n",
    "    results = defaultdict(list)\n",
    "    for i in range(0, B, chunk):\n",
    "        kwargs_ = {}\n",
    "        if 'a_embedded' in kwargs:\n",
    "            kwargs_['a_embedded'] = kwargs['a_embedded'][i:i+chunk]\n",
    "        rendered_ray_chunks = \\\n",
    "            render_rays(models,\n",
    "                        embeddings,\n",
    "                        rays[i:i+chunk],\n",
    "                        ts[i:i+chunk],\n",
    "                        N_samples,\n",
    "                        use_disp,\n",
    "                        0,\n",
    "                        0,\n",
    "                        N_importance,\n",
    "                        chunk,\n",
    "                        dataset.white_back,\n",
    "                        test_time=True,\n",
    "                        **kwargs_)\n",
    "\n",
    "        for k, v in rendered_ray_chunks.items():\n",
    "            results[k] += [v]\n",
    "\n",
    "    for k, v in results.items():\n",
    "        results[k] = torch.cat(v, 0)\n",
    "    del rendered_ray_chunks\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/OPEN_patient/segment_001/datasets/'\n",
    "\n",
    "dataset = dataset_dict['phototourism'] \\\n",
    "          (root_dir,\n",
    "           split='test_train',\n",
    "           img_downscale=3, \n",
    "           use_cache=False, \n",
    "           tsv_file='OPEN_scale3_nerfw.tsv',\n",
    "           exp_name='eval_OPEN_scale3_nerfw_top_bottom_load_gt_and_mask',\n",
    "           mask_path=f'{root_dir}/mask.png',\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_test = dataset.img_ids_test\n",
    "print(len(img_ids_test))\n",
    "for idx in img_ids_test:\n",
    "    print(dataset.image_paths[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "samples = {}\n",
    "\n",
    "for idx in img_ids_test:\n",
    "    print(f\"Calculating results for id: {idx}...\")\n",
    "    sample = dataset[idx]\n",
    "    sample['dataset_path'] = dataset.image_paths[idx]\n",
    "    img_w, img_h = sample[\"img_wh\"]\n",
    "\n",
    "    rays = sample[\"rays\"].cuda()\n",
    "    ts = sample[\"ts\"].cuda()\n",
    "    rgbs = sample[\"rgbs\"]\n",
    "\n",
    "    rgbs = rgbs.view(img_h, img_w, -1)\n",
    "    rgbs_top, rgbs_bottom = torch.split(rgbs, [img_h // 2, img_h // 2], dim=0)\n",
    "    rgbs_top = rgbs_top.contiguous().view(-1)\n",
    "\n",
    "    sample[\"rgbs_top\"] = rgbs_top\n",
    "    samples[idx] = sample\n",
    "    results[idx] = {k: v.cpu() for k, v in (f(rays, ts)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dataset.mask.permute(1,2,0)\n",
    "# mask_dir = os.path.join(root_dir, 'mask.png')\n",
    "# mask = Image.open(mask_dir).convert('RGB').resize((360,360), Image.LANCZOS)\n",
    "# mask = T.ToTensor()(mask).permute(1,2,0)\n",
    "\n",
    "\n",
    "img_w, img_h = mask.shape[0], mask.shape[1]\n",
    "\n",
    "mask_top, mask_bottom = torch.split(mask, [img_h//2, img_h//2], dim=0)\n",
    "\n",
    "plt.subplots(figsize=(15, 8))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.subplot(131)\n",
    "plt.title('mask')\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.title('mask top')\n",
    "plt.imshow(mask_top, cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.title('mask bottom')\n",
    "plt.imshow(mask_bottom, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_img(mask, img):\n",
    "    img = img if torch.is_tensor(img) else torch.from_numpy(img)\n",
    "    return img * mask\n",
    "\n",
    "def plot_print_results(sample, result,mask, encode_transient, save_output=False):\n",
    "    img_w, img_h = tuple(sample['img_wh'].numpy())\n",
    "    img_name = sample['dataset_path']\n",
    "\n",
    "\n",
    "    # get whole GT and top half\n",
    "    img_gt = sample['rgbs'].reshape(img_h, img_w, 3)\n",
    "    img_gt_top = sample['rgbs_top'].reshape(img_h // 2, img_w, 3)\n",
    "\n",
    "    # gt_dir = os.path.join(root_dir, 'images', img_name)\n",
    "    # img_gt = Image.open(gt_dir).convert('RGB').resize((img_h,img_w), Image.LANCZOS)\n",
    "    # img_gt = T.ToTensor()(img_gt).permute(1,2,0)\n",
    "    # img_gt_top, img_gt_bottom = torch.split(img_gt, [img_h//2, img_h//2], dim=0)\n",
    "\n",
    "    # get whole pred and split in half\n",
    "    img_pred = result['rgb_fine'].reshape(img_h, img_w, 3)\n",
    "    img_pred_top, img_pred_bottom = torch.split(img_pred, [img_h//2, img_h//2], dim=0)\n",
    "\n",
    "    depth_pred = result['depth_fine'].reshape(img_h, img_w)\n",
    "\n",
    "    # mask GTs and preds\n",
    "    img_gt = masked_img(mask,img_gt)\n",
    "    img_gt_top = masked_img(mask_top,img_gt_top)\n",
    "\n",
    "    masked_pred = masked_img(mask,img_pred)\n",
    "    masked_pred_top = masked_img(mask_top,img_pred_top)\n",
    "\n",
    "\n",
    "    if save_output:\n",
    "        # save results\n",
    "        img_dir = os.path.join(root_dir, 'results','nerf-w', 'images')\n",
    "        depth_dir = os.path.join(root_dir, 'results','nerf-w', 'depth')\n",
    "\n",
    "        # create dirs if not exist\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(depth_dir, exist_ok=True)\n",
    "\n",
    "        depth_name = f'{img_name[:-4]}_depth.png'\n",
    "\n",
    "        depth_img = (visualize_depth(depth_pred) * 255).to(torch.uint8)\n",
    "        pred_img = (img_pred * 255).permute(2,0,1).to(torch.uint8)\n",
    "\n",
    "        write_png(pred_img, os.path.join(img_dir, img_name))\n",
    "        write_png(depth_img, os.path.join(depth_dir, depth_name))\n",
    "\n",
    "\n",
    "    # plot results\n",
    "    plt.subplots(figsize=(15, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(241)\n",
    "    plt.title(\"GT masked\")\n",
    "    plt.imshow(img_gt)\n",
    "\n",
    "    plt.subplot(242)\n",
    "    plt.title(\"pred\")\n",
    "    plt.imshow(img_pred)\n",
    "\n",
    "    plt.subplot(243)\n",
    "    plt.title(\"pred with mask\")\n",
    "    plt.imshow(masked_pred)\n",
    "\n",
    "    plt.subplot(244)\n",
    "    plt.title(\"depth\")\n",
    "    plt.imshow(visualize_depth(depth_pred).permute(1, 2, 0))\n",
    "\n",
    "    plt.subplot(245)\n",
    "    plt.title(\"GT top\")\n",
    "    plt.imshow(img_gt_top)\n",
    "\n",
    "    plt.subplot(246)\n",
    "    plt.title(\"pred top\")\n",
    "    plt.imshow(img_pred_top)\n",
    "\n",
    "    plt.subplot(247)\n",
    "    plt.title(\"pred top masked\")\n",
    "    plt.imshow(masked_pred_top)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # valid mask\n",
    "    valid_mask = (mask_top != 0).repeat(1,1,3)\n",
    "    # valid_mask = (mask_top != 0)\n",
    "\n",
    "    # calculate scores on top half of image\n",
    "    psnr_ = metrics.psnr(img_gt_top, img_pred_top).item()\n",
    "    ssim_ = metrics.ssim(img_gt_top, img_pred_top).item()\n",
    "    lpips_ = metrics.lpips_score(img_gt_top, img_pred_top).item()\n",
    "\n",
    "    psnr_mask_ = metrics.psnr(img_gt_top, masked_pred_top).item()\n",
    "    psnr_unmask_ = metrics.psnr(img_gt_top, masked_pred_top, valid_mask=valid_mask).item()\n",
    "    ssim_mask_ = metrics.ssim(img_gt_top, masked_pred_top).item()\n",
    "    lpips_mask_ = metrics.lpips_score(img_gt_top, masked_pred_top).item()\n",
    "\n",
    "    print(f'{\"#\"*15} Scores for real predicition {\"#\"*15}')\n",
    "    print('PSNR between GT and pred:', psnr_)\n",
    "    print('SSIM between GT and pred:', ssim_)\n",
    "    print('LPIPS between GT and pred:',lpips_, '\\n') \n",
    "\n",
    "    print(f'{\"#\"*15} Scores for masked predicition {\"#\"*15}')\n",
    "    print('PSNR between GT and pred:', psnr_mask_)\n",
    "    print('UNMASKED PSNR between GT and pred:', psnr_unmask_)\n",
    "    print('SSIM between GT and pred:', ssim_mask_)\n",
    "    print('LPIPS between GT and pred:',lpips_mask_) \n",
    "\n",
    "\n",
    "\n",
    "    if encode_transient:\n",
    "        print('Decomposition--------------------------------------------' + \n",
    "            '---------------------------------------------------------' +\n",
    "            '---------------------------------------------------------' + \n",
    "            '---------------------------------------------------------')\n",
    "        valid_mask_static = sample['valid_mask'].reshape(img_wh[1], img_wh[0])\n",
    "        beta = result['beta'].reshape(img_wh[1], img_wh[0])\n",
    "        img_pred_static = result['rgb_fine_static'].reshape(img_wh[1], img_wh[0], 3)\n",
    "        img_pred_transient = result['_rgb_fine_transient'].reshape(img_wh[1], img_wh[0], 3)\n",
    "        depth_pred_static = result['depth_fine_static'].reshape(img_wh[1], img_wh[0])\n",
    "        depth_pred_transient = result['depth_fine_transient'].reshape(img_wh[1], img_wh[0])\n",
    "        plt.subplots(figsize=(15, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(231)\n",
    "        plt.title('static')\n",
    "        plt.imshow(img_pred_static)\n",
    "        plt.subplot(232)\n",
    "        plt.title('transient')\n",
    "        plt.imshow(img_pred_transient)\n",
    "        plt.subplot(233)\n",
    "        plt.title('uncertainty (beta)')\n",
    "        plt.imshow(beta-beta_min, cmap='gray')\n",
    "        plt.subplot(234)\n",
    "        plt.title('static depth')\n",
    "        plt.imshow(visualize_depth(depth_pred_static).permute(1,2,0))\n",
    "        plt.subplot(235)\n",
    "        plt.title('valid mask')\n",
    "        plt.imshow(valid_mask_static, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    return psnr_,psnr_mask_,psnr_unmask_, ssim_, ssim_mask_, lpips_, lpips_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = []\n",
    "ssims = []\n",
    "lpips_scores = []\n",
    "\n",
    "psnrs_mask = []\n",
    "psnrs_unmask = []\n",
    "ssims_mask = []\n",
    "lpips_scores_mask = []\n",
    "\n",
    "# don't evaluate on images with transient objects\n",
    "# skipped_images = [0,1,2,3]\n",
    "skipped_images = []\n",
    "save_output = True if 'OPEN' in root_dir else False\n",
    "for i,idx in enumerate(img_ids_test):\n",
    "     if i in skipped_images:\n",
    "          continue\n",
    "     sample = samples[idx]\n",
    "     result = results[idx]\n",
    "     \n",
    "     psnr,psnr_mask,psnr_unmask, ssim,ssim_mask, lpips, lpips_mask = plot_print_results(sample=sample, result=result,mask=mask, encode_transient=False, save_output=save_output)\n",
    "     \n",
    "     psnrs.append(psnr)\n",
    "     psnrs_unmask.append(psnr_unmask)\n",
    "     ssims.append(ssim)\n",
    "     lpips_scores.append(lpips)\n",
    "\n",
    "     psnrs_mask.append(psnr_mask)\n",
    "     ssims_mask.append(ssim_mask)\n",
    "     lpips_scores_mask.append(lpips_mask)\n",
    "\n",
    "\n",
    "# Masked\n",
    "\n",
    "# PSNR\n",
    "mean_psnr = round(np.mean(psnrs_mask),2)\n",
    "median_psnr = round(np.median(psnrs_mask),2)\n",
    "max_psnr = round(np.max(psnrs_mask),2)\n",
    "min_psnr = round(np.min(psnrs_mask),2)\n",
    "\n",
    "mean_psnr_unmask = round(np.mean(psnrs_unmask),2)\n",
    "median_psnr_unmask = round(np.median(psnrs_unmask),2)\n",
    "max_psnr_unmask = round(np.max(psnrs_unmask),2)\n",
    "min_psnr_unmask = round(np.min(psnrs_unmask),2)\n",
    "\n",
    "# SSIM\n",
    "mean_ssim = round(np.mean(ssims_mask),3)\n",
    "median_ssim = round(np.median(ssims_mask),3)\n",
    "max_ssim = round(np.max(ssims_mask),3)\n",
    "min_ssim = round(np.min(ssims_mask),3)\n",
    "\n",
    "# LPIPS\n",
    "mean_lpips = round(np.mean(lpips_mask),4)\n",
    "median_lpips = round(np.median(lpips_mask),4)\n",
    "max_lpips = round(np.max(lpips_mask),4)\n",
    "min_lpips = round(np.min(lpips_mask),4)\n",
    "\n",
    "\n",
    "print(f'{\"#\"*15} Mean scores for masked prediction {\"#\"*15}')\n",
    "print(\"Mean PSNR: \", mean_psnr)\n",
    "print(\"Mean UNMASKED PSNR: \", mean_psnr_unmask)\n",
    "print(\"Mean SSIM: \", mean_ssim)\n",
    "print(\"Mean LPIPS: \", mean_lpips)\n",
    "\n",
    "data = {\n",
    "     'mean_psnr': mean_psnr,\n",
    "     'median_psnr': median_psnr,\n",
    "     'max_psnr': max_psnr,\n",
    "     'min_psnr': min_psnr,\n",
    "     'mean_psnr_unmasked': mean_psnr_unmask,\n",
    "     'median_psnr_unmasked': median_psnr_unmask,\n",
    "     'max_psnr_unmasked': max_psnr_unmask,\n",
    "     'min_psnr_unmasked': min_psnr_unmask,\n",
    "     'mean_ssim': mean_ssim,\n",
    "     'median_ssim': median_ssim,\n",
    "     'max_ssim': max_ssim,\n",
    "     'min_ssim': min_ssim,\n",
    "     'mean_lpips': mean_lpips,\n",
    "     'median_lpips': median_lpips,\n",
    "     'max_lpips': max_lpips,\n",
    "     'min_lpips': min_lpips\n",
    "}\n",
    "\n",
    "json_obj = json.dumps(data)\n",
    "results_file = f'results_{dataset.exp_name}.json' if not skipped_images else f'results_{dataset.exp_name}_skipped_images.json'\n",
    "with open(os.path.join(root_dir,'results', results_file),'w') as file:\n",
    "     file.write(json_obj)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "#del samples\n",
    "#del results\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate embedding for appearance change (Fig 8 in the paper)\n",
    "### left image: train number 53; right image: train number 111\n",
    "### The pose is fixed to that of the right image, and the appearance embedding is interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_sample = dataset[53]\n",
    "# right_sample = dataset[111]\n",
    "\n",
    "# right_rays = right_sample['rays'].cuda()\n",
    "# right_ts = right_sample['ts'].cuda()\n",
    "# left_a_embedded = embedding_a(left_sample['ts'][0].cuda())\n",
    "# right_a_embedded = embedding_a(right_sample['ts'].cuda())\n",
    "\n",
    "# results_list = [left_sample]\n",
    "\n",
    "# for i in range(5):\n",
    "#     kwargs = {'a_embedded': right_a_embedded*i/4+left_a_embedded*(1-i/4)}\n",
    "#     results_list += [f(right_rays, right_ts, **kwargs)]\n",
    "\n",
    "# results_list += [right_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(20, 10))\n",
    "# for i, results in enumerate(results_list):\n",
    "#     if i == 0:\n",
    "#         img_wh = tuple(results['img_wh'].numpy())\n",
    "#         left_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(241)\n",
    "#         plt.axis('off')\n",
    "#         plt.title('left GT')\n",
    "#         plt.imshow(left_GT)\n",
    "#     elif i == 6:\n",
    "#         img_wh = tuple(results['img_wh'].numpy())\n",
    "#         right_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(247)\n",
    "#         plt.axis('off')\n",
    "#         plt.title('right GT')\n",
    "#         plt.imshow(right_GT)\n",
    "#     else:\n",
    "#         img_wh = tuple(right_sample['img_wh'].numpy())\n",
    "#         img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
    "#         plt.subplot(2, 4, i+1)\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img_pred)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\n",
    "    os.path.join(root_dir, \"images\", '00000.png')\n",
    ").convert(\"RGB\")\n",
    "\n",
    "img_w, img_h = img.size\n",
    "img_w = img_w // 3\n",
    "img_h = img_h // 3\n",
    "img = img.resize((img_w, img_h), Image.LANCZOS)\n",
    "\n",
    "img_tensor = T.ToTensor()(img).permute(1,2,0)\n",
    "print(img_tensor.shape)\n",
    "plt.tight_layout()\n",
    "plt.subplots(figsize=(15, 8))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.subplot(132)\n",
    "plt.imshow(mask)\n",
    "plt.subplot(133)\n",
    "plt.imshow(img_tensor*mask)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
